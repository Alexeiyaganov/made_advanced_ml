{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-1: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные: https://www.dropbox.com/s/s4qj0fpsn378m2i/chgk.zip \n",
    "\n",
    "Прочитайте и проанализируйте данные, выберите турниры, в которых есть данные о составах команд и повопросных результатах (поле mask в results.pkl). Для унификации предлагаю:\n",
    "* взять в тренировочный набор турниры с dateStart из 2019 года; \n",
    "* в тестовый — турниры с dateStart из 2020 года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-file/32216025\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Достаем ids турниров (2019 -- train, 2020 -- test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109, 687, 422)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tournaments = pd.DataFrame(pd.read_pickle('chgk/tournaments.pkl')).transpose()\n",
    "df_tournaments = df_tournaments[df_tournaments.dateStart >= '2019-01-01']\n",
    "\n",
    "tournaments_ids_all = df_tournaments[df_tournaments.dateStart >= '2019-01-01']\n",
    "tournaments_ids_all = set(tournaments_ids_all['id'])\n",
    "save_obj(tournaments_ids_all, 'tournaments_ids_all')\n",
    "\n",
    "tournaments_ids_test = df_tournaments[df_tournaments.dateStart >= '2020-01-01']\n",
    "tournaments_ids_test = set(tournaments_ids_test['id'])\n",
    "save_obj(tournaments_ids_test, 'tournaments_ids_test')\n",
    "\n",
    "tournaments_ids_train = tournaments_ids_all.difference(tournaments_ids_test)\n",
    "save_obj(tournaments_ids_train, 'tournaments_ids_train')\n",
    "\n",
    "len(tournaments_ids_all), len(tournaments_ids_train), len(tournaments_ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Среди всех турниров оставляем только турниры:\n",
    "* нужных лет (2019-2020);\n",
    "* с mask для всех участников (повопросные ответы)\n",
    "* с teamMembers для всех участников (данные об участниках)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataframe length =  5528\n",
      "cleared dataframe length =  169\n"
     ]
    }
   ],
   "source": [
    "def get_results_df(tournament_ids):\n",
    "    df_results = pd.read_pickle('chgk/results.pkl')\n",
    "    print(\"full dataframe length = \", len(df_results))\n",
    "    results_all = {}\n",
    "    for k, v in df_results.items():\n",
    "        # игнорируем турниры до 2019 года, а также пустые записи\n",
    "        if k in tournament_ids and len(v) > 0:\n",
    "            valid = True\n",
    "            # игнорируем турниры, где нет нужных нам валидных полей\n",
    "            for team_data in v:\n",
    "                if 'team' not in team_data or 'mask' not in team_data or 'teamMembers' not in team_data:\n",
    "                    valid = False\n",
    "                    continue\n",
    "                if team_data['mask'] is None or team_data['team'] is None or team_data['teamMembers'] is None:\n",
    "                    valid = False\n",
    "                    continue\n",
    "            if valid:\n",
    "                results_all[k] = v\n",
    "    print(\"cleared dataframe length = \", len(results_all))\n",
    "    return results_all\n",
    "\n",
    "df_test = get_results_df(tournaments_ids_test)\n",
    "save_obj(df_test, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем в датафрейм ('tournament_id', 'team_id', 'player_id', 'mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataframe length =  5528\n",
      "cleared dataframe length =  671\n"
     ]
    }
   ],
   "source": [
    "def unwrap_player(df):\n",
    "    df_results_cleaned = []\n",
    "    for k, v in df.items():\n",
    "        for team_data in v:\n",
    "            team = team_data['team']\n",
    "            mask = str(team_data['mask']).replace('X', '0').replace('?', '0')\n",
    "            players = team_data['teamMembers']\n",
    "            for player in players:\n",
    "                df_results_cleaned.append([k, team['id'], player['player']['id'], mask])\n",
    "    df = pd.DataFrame(df_results_cleaned)\n",
    "    df.columns = ['tournament_id', 'team_id', 'player_id', 'mask']\n",
    "    return df\n",
    "\n",
    "df_train = get_results_df(tournaments_ids_train)\n",
    "df_train = unwrap_player(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем в датафрейм ('tournament_id', 'team_id', 'player_id', 'question_local_id', 'target')\n",
    "#### Замечание: для этого разворачиваем mask -> (question_local_id, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_mask(df):\n",
    "    df_results_cleaned = []\n",
    "    for _, row in df.iterrows():\n",
    "        tt_id = row['tournament_id']\n",
    "        tm_id = row['team_id']\n",
    "        pr_id = row['player_id']\n",
    "        mask = row['mask']\n",
    "        for idx in range(len(mask)):\n",
    "            df_results_cleaned.append([tt_id, tm_id, pr_id, idx, mask[idx]])\n",
    "    df = pd.DataFrame(df_results_cleaned)\n",
    "    df.columns = ['tournament_id', 'team_id', 'player_id', 'question_local_id', 'target']\n",
    "    return df\n",
    "\n",
    "df_train = unwrap_mask(df_train)\n",
    "save_obj(df_train, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте baseline-модель на основе линейной или логистической регрессии, которая будет обучать рейтинг-лист игроков. Замечания и подсказки:\n",
    "\n",
    "повопросные результаты — это фактически результаты броска монетки, и их предсказание скорее всего имеет отношение к бинарной классификации;\n",
    "в разных турнирах вопросы совсем разного уровня сложности, поэтому модель должна это учитывать; скорее всего, модель должна будет явно обучать не только силу каждого игрока, но и сложность каждого вопроса;\n",
    "для baseline-модели можно забыть о командах и считать, что повопросные результаты команды просто относятся к каждому из её игроков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Схема baseline:\n",
    "\n",
    "C помощью логистической регрессии будем предсказывать $z_{i,j}$ -- вероятность ответил ли игрок i на вопрос в рамках турнира j:\n",
    "* Преобразуем 'tournament_id', 'player_id' в one-hot-фичи, 'team_id' и 'question_local_id' не используем;\n",
    "* Обучаем logreg на целевой переменной target (ответил / не ответил на вопрос данного турнира);\n",
    "* Сохраняем финальные веса фичей пользователей (one-hot из player_id), вес пользователя интерпретируем как его \"силу\", и за счет ранжирования весов получаем рейтинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 1 of 2) Processing feature_generation, total=  11.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=35.7min\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_MODE:\n",
    "    # get preprocessed df ('tournament_id', 'team_id', 'player_id', 'question_local_id', 'target')\n",
    "    df = pd.read_csv('train.zip').drop(columns=['team_id', 'question_local_id'])\n",
    "    \n",
    "    # construct pipeline with one-hot-encoder and logreg\n",
    "    feature_generation = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('OneHot', OneHotEncoder(), ['tournament_id', 'player_id'])\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        sparse_threshold=1\n",
    "    )\n",
    "    pipe = Pipeline(\n",
    "        verbose=True,\n",
    "        steps=[\n",
    "            ('feature_generation', feature_generation),\n",
    "            ('classifier', LogisticRegression(solver='liblinear', max_iter=100))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # train\n",
    "    pipe.fit(df[['tournament_id', 'player_id']], df['target'])\n",
    "    \n",
    "    # save player weights (~raiting)\n",
    "    player_features_start_pos = df.nunique()['tournament_id']\n",
    "    player_features_names = pipe['feature_generation'].get_feature_names()[player_features_start_pos:]\n",
    "    assert(len(player_features_names) == df.nunique()['player_id'])\n",
    "    player_ids = [int(name[11:]) for name in player_features_names]\n",
    "    \n",
    "    player_weights = pipe['classifier'].coef_[0][player_features_start_pos:]\n",
    "    assert(len(player_weights) == df.nunique()['player_id'])\n",
    "    \n",
    "    player_to_weight = dict(zip(player_ids, player_weights))\n",
    "    save_obj(player_to_weight, 'player_to_weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Грубая проверка: сравним top-100 официального рейтинга и предсказания\n",
    "Официальный рейтинг: https://rating.chgk.info/players.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAIN_MODE:\n",
    "    player_to_weight = load_obj('player_to_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'players-official-top-1000.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SKIENB~1\\AppData\\Local\\Temp/ipykernel_20268/1120199801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mofficial_top_100_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'players-official-top-1000.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mofficial_top_100_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofficial_top_100_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' ИД'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1661\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'players-official-top-1000.csv'"
     ]
    }
   ],
   "source": [
    "official_top_100_ids = pd.read_csv('players-official-top-1000.csv')[:100]\n",
    "official_top_100_ids = set(official_top_100_ids[' ИД'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_to_weight_sorted = sorted(player_to_weight.items(), key=lambda kv: kv[1], reverse=True)\n",
    "predicted_top_100_ids = set(k for k, v in player_to_weight_sorted[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'official_top_100_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SKIENB~1\\AppData\\Local\\Temp/ipykernel_20268/3691534354.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mofficial_top_100_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_top_100_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'official_top_100_ids' is not defined"
     ]
    }
   ],
   "source": [
    "len(official_top_100_ids.intersection(predicted_top_100_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель смогла предсказать больше 53 игрока из топ 100.\n",
    "#### Т.е грубая проверка показывает, что большие веса получили сильные игроки. Основная валидация на тестовых данных в Part-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество рейтинг-системы оценивается качеством предсказаний результатов турниров. Но сами повопросные результаты наши модели предсказывать вряд ли смогут, ведь неизвестно, насколько сложными окажутся вопросы в будущих турнирах; да и не нужны эти предсказания сами по себе. Поэтому:\n",
    "* предложите способ предсказать результаты нового турнира с известными составами, но неизвестными вопросами, в виде ранжирования команд;\n",
    "* в качестве метрики качества на тестовом наборе давайте считать ранговые корреляции Спирмена и Кендалла (их можно взять в пакете scipy) между реальным ранжированием в результатах турнира и предсказанным моделью, усреднённые по тестовому множеству турниров.\n",
    "\n",
    "Для самопроверки: у Сергея средняя корреляция Спирмена на тестовом множестве 2020 года во всех моделях, включая baselines, получалась порядка 0.7-0.8, а корреляция Кендалла — порядка 0.5-0.6. Если у корреляции вышли за 0.9 или, наоборот, упали ниже 0.3, скорее всего где-то баг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Вес (сила) команды = вес ее участников (их обучили на трейне)\n",
    "#### * В рамках одного турнира предлагается ранжировать команды по их весу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_to_weight = load_obj('player_to_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_obj('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions_label(tournament):\n",
    "    return [team['position'] for team in tournament]\n",
    "\n",
    "def get_position_prediction(tournament):\n",
    "    \"\"\"\n",
    "    ранжируем команды по весу = (сумма весов участников),\n",
    "    есть игрока не было в train -- берем средний вес игрока в трейне\n",
    "    \"\"\"\n",
    "    avg_weight = np.mean([v for v in player_to_weight.values()])\n",
    "    team_rating = []\n",
    "    for idx, team in enumerate(tournament):\n",
    "        weight = 0\n",
    "        for player_info in team['teamMembers']:\n",
    "            p_id = player_info['player']['id']\n",
    "            try:\n",
    "                weight += player_to_weight[p_id]\n",
    "            except:\n",
    "                weight += avg_weight\n",
    "        team_rating.append((idx + 1, weight))\n",
    "    team_rating = sorted(team_rating, key=lambda kv: kv[1], reverse=True)\n",
    "    return [pos for pos, weight in team_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Spearman corr value for df = 0.7821800575848492\n",
      "Avg Kendall  corr value for df = 0.6252692792756139\n"
     ]
    }
   ],
   "source": [
    "def get_score(df, corr):\n",
    "    x = [corr(get_positions_label(t), get_position_prediction(t)).correlation for t in df.values()]\n",
    "    x = np.array(x)\n",
    "    x = x[~np.isnan(x)]\n",
    "    return np.mean(x)\n",
    "\n",
    "for corr in [('Spearman', stats.spearmanr), ('Kendall ', stats.kendalltau)]:\n",
    "    print(f'Avg {corr[0]} corr value for df = {get_score(df_test, corr[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-4: EM algorithm\n",
    "\n",
    "Теперь главное: ЧГК — это всё-таки командная игра. Поэтому:\n",
    "* предложите способ учитывать то, что на вопрос отвечают сразу несколько игроков; скорее всего, понадобятся скрытые переменные; не стесняйтесь делать упрощающие предположения, но теперь переменные “игрок X ответил на вопрос Y” при условии данных должны стать зависимыми для игроков одной и той же команды;\n",
    "* разработайте EM-схему для обучения этой модели, реализуйте её в коде;\n",
    "* обучите несколько итераций, убедитесь, что целевые метрики со временем растут (скорее всего, ненамного, но расти должны), выберите лучшую модель, используя целевые метрики.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение\n",
    "\n",
    "### M-step\n",
    "* В рамках baseline (part 2) мы научились предсказывать $p(z_{i,j}=1)$ -- вероятность ответил ли игрок i на вопрос j, веса фичей пользователя обученной модели мы интерпретировали как их \"силу\";\n",
    "* Если выбрать $z_{i, j}$ в качестве скрытых переменных, то M-шаг сводится к дообучению модели при заданных $z_(i, j)$, начальные веса совпадают с исходными метками $x_{i,j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>target</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45556</td>\n",
       "      <td>6212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   team_id  player_id  target question_id\n",
       "0    45556       6212       1      4772_0\n",
       "1    45556       6212       1      4772_1\n",
       "2    45556       6212       1      4772_2\n",
       "3    45556       6212       1      4772_3\n",
       "4    45556       6212       1      4772_4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data: describe and computed in part 1\n",
    "n_epoch = 5\n",
    "df_train = pd.read_csv('train.zip')\n",
    "df_train[\"question_id\"] = df_train['tournament_id'].astype(str) + '_' + df_train['question_local_id'].astype(str)\n",
    "df_train = df_train.drop(columns=['tournament_id', 'question_local_id'])\n",
    "X, y = df_train[['player_id', 'question_id']], df_train['target']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m-step model: described in part 2\n",
    "\n",
    "feature_generation = ColumnTransformer(\n",
    "    transformers=[('OneHot', OneHotEncoder(), ['player_id', 'question_id'])],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=1\n",
    ")\n",
    "\n",
    "# Замечание: пришлось заменить sklearn::LogisticRegression, тк в ходе выполнения задания\n",
    "# выяснилось, что она плохо работает с небинарными таргетами, поэтому заменил ее на другой регрессор:\n",
    "# https://stackoverflow.com/questions/47663569/how-to-do-regression-as-opposed-to-classification-using-logistic-regression-and\n",
    "pipe = Pipeline(\n",
    "    verbose=True,\n",
    "    steps=[\n",
    "        ('feature_generation', feature_generation),\n",
    "        ('regressor', LinearSVR(loss='squared_epsilon_insensitive'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "def m_step(model, X, y):\n",
    "    model.fit(X, y)\n",
    "    return model, model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_player_weights(X, model):\n",
    "    \"\"\"\n",
    "    сохраняем веса фичей пользователей из обученного классификатора\n",
    "    \"\"\"\n",
    "    player_features_end_pos = X.nunique()['question_id']\n",
    "    player_features_names = model['feature_generation'].get_feature_names()[0:player_features_end_pos]\n",
    "    player_ids = [int(name[11:]) for name in player_features_names]\n",
    "    player_weights = model['regressor'].coef_[0:player_features_end_pos]\n",
    "    player_to_weight = dict(zip(player_ids, player_weights))\n",
    "    return player_to_weight\n",
    "\n",
    "#_, preds = m_step(pipe, X, y)\n",
    "#validate(load_obj('test'), save_player_weights(X, _))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-step\n",
    "\n",
    "* Теперь хотим учесть наличие команды, тч $z_{i,j}$ стали зависимыми для игроков одной команды, перейдем к прогнозированию условных вероятностей $p(z_{i,j} = 1)$ -> $p(z_{i,j} = 1 | team_{i, j} = 1)$, где $team_{i, j}$ -- ответила ли команда игрока i на вопрос j;\n",
    "* Предположим, что $$team_{i, j} = 1 \\iff \\exists k \\in team_i : z_{k, j} = 1$$\n",
    "* И наоборот: $$team_{i, j} = 0 \\iff \\forall k \\in team_i : z_{k, j} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По теореме Байеса имеем:\n",
    "$$\n",
    "    p(z_{i,j}=1|team_{i,j}=1) = \\frac{p(team_{i,j}=1|z_{i,j}=1) p(z_{i,j}=1)}{p(team_{i,j}=1)}\n",
    "$$\n",
    "\n",
    "C учетом предположений имеем:\n",
    "$$\n",
    "    p(z_{i,j}=1|team_{i,j}=1) = \\frac{p(z_{i,j}=1)}{1 - p(team_{i,j}=0)} = \\frac{p(z_{i,j}=1)}{1 - \\Pi_{k \\in team_i} \\left(1 - p(z_{k,j}=1)\\right)}\n",
    "$$\n",
    "\n",
    "С учетом того, что $p(z_{i,j}=1)$ являются результатом M-шага, то формула выше может быть использована для E-шага"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(df, preds):\n",
    "    df['new_target'] = preds\n",
    "    label_zero_idx = df['target'] == 0\n",
    "    df.loc[label_zero_idx, 'new_target'] = 0\n",
    "    # изменяем только метки для вопросов, на которые команда ответила\n",
    "    # поскольку p(z_ij = 1 | team_ij = 0) = 0 в силу предположений\n",
    "    label_one_idx = df['target'] == 1\n",
    "    e_step_denom = df.loc[label_one_idx].groupby(['team_id', 'question_id'])['new_target']\n",
    "    e_step_denom = e_step_denom.transform(lambda x : 1 - np.prod(1 - x.values))\n",
    "    df.loc[label_one_idx, 'new_target'] = df.loc[label_one_idx, 'new_target'] / e_step_denom\n",
    "    new_y = df['new_target'].fillna(0)\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "pipe, preds = m_step(pipe, X, y)\n",
    "#validate(load_obj('test'), save_player_weights(X, pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM-iterations\n",
    "for i in range(n_epoch):\n",
    "    y = e_step(df_train, preds)\n",
    "    pipe, preds = m_step(pipe, X, y)\n",
    "    weights = save_player_weights(X, pipe)\n",
    "    save_obj(weights, f'em_weights_epoch_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation: described in part 3\n",
    "\n",
    "def get_positions_label(tournament):\n",
    "    \"\"\"\n",
    "    позиции команд в турнире (фактические)\n",
    "    \"\"\"\n",
    "    return [team['position'] for team in tournament]\n",
    "\n",
    "\n",
    "def get_position_prediction(tournament, player_to_weight):\n",
    "    \"\"\"\n",
    "    позиции команд в турнире (предсказанные),\n",
    "    ранжируем команды по весу = (сумма весов участников),\n",
    "    есть игрока не было в train -- берем средний вес игрока в трейне\n",
    "    \"\"\"\n",
    "    avg_weight = np.mean([v for v in player_to_weight.values()])\n",
    "    team_rating = []\n",
    "    for idx, team in enumerate(tournament):\n",
    "        weight = 0\n",
    "        for player_info in team['teamMembers']:\n",
    "            p_id = player_info['player']['id']\n",
    "            try:\n",
    "                weight += player_to_weight[p_id]\n",
    "            except:\n",
    "                weight += avg_weight\n",
    "        team_rating.append((idx + 1, weight))\n",
    "    team_rating = sorted(team_rating, key=lambda kv: kv[1], reverse=True)\n",
    "    return [pos for pos, weight in team_rating]\n",
    "\n",
    "\n",
    "def get_score(df_test, player_to_weight, corr):\n",
    "    \"\"\"\n",
    "    среднее значение rank correlation по тестовой выборке\n",
    "    \"\"\"\n",
    "    x = [corr(get_positions_label(t), get_position_prediction(t, player_to_weight)).correlation for t in df_test.values()]\n",
    "    x = np.array(x)\n",
    "    x = x[~np.isnan(x)]\n",
    "    return np.mean(x)\n",
    "\n",
    "def validate(df_test, player_to_weight, corr=None):\n",
    "    if corr is None:\n",
    "        for corr in [('Spearman', stats.spearmanr), ('Kendall ', stats.kendalltau)]:\n",
    "            print(f'Avg {corr[0]} corr value for df = {get_score(df_test, player_to_weight, corr[1])}')\n",
    "    else:\n",
    "        print(f'Avg {corr[0]} corr value for df = {get_score(df_test, player_to_weight, corr[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_epoch):\n",
    "    print(f'Epoch {i+1}:')\n",
    "    validate(load_obj('test'), load_obj(f'em_weights_epoch_{i}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики не растут. В чем дело? Ход разбирательства:\n",
    "\n",
    "* Бейзлайн модель LogisticRegression, метрики падали сильнейшим образом, выяснил что данная модель из sklearn некорректно работает с небинарными таргетами, а именно они возникают на итерациях EM-алгоритм;\n",
    "* Заменил модель на LinearSVR, настроил параметры: метрики все также не растут, но хотя бы перестали убывать;\n",
    "* Заменил фичи m-step модели: (tournament_id, player_id) -> (player_id, question_id), по рост скачком выглядит подозрительно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
